\relax 
\providecommand*\new@tpo@label[2]{}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{Definitions/mdpi}
\citation{nn1,nn2}
\citation{nnphysics1,nnphysics2,nnphysics3}
\citation{nnde1}
\citation{nn_solar}
\citation{nnagr2}
\citation{nnchem1,nnchem3}
\citation{nnecon1,nnecon2}
\citation{nnmed1,nnmed2}
\citation{bpnn1,bpnn2}
\citation{rpropnn-1}
\citation{Adam}
\citation{nn_ann1}
\citation{geneticnn}
\citation{psonn}
\citation{weight_aco}
\citation{tabunn}
\citation{nn_hybrid}
\citation{weight_abc}
\citation{nn_cascade}
\newmarginnote{note.1.1}{{1}{10945661sp}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{eq:eq1}{{1}{1}{Introduction}{equation.1.1}{}}
\citation{nn_init1}
\citation{nn_init2}
\citation{nn_init3}
\citation{nn_init4}
\citation{nn_arch1,nn_arch2}
\citation{nn_arch3}
\citation{nn_arch4}
\citation{nnsharing1,nnsharing2}
\citation{nnprunning1,nnprunning2}
\citation{nnearly1,nnearly2}
\citation{nndecay1,nndecay2}
\citation{de_review}
\citation{de1,de2}
\citation{de_symmetry1}
\citation{de_symmetry3}
\citation{de_symmetry6}
\citation{de_symmetry7}
\citation{key-16,de_problem2}
\citation{de_problem3,de_problem4}
\citation{de_deep1,de_deep2}
\citation{nn_deep1,nn_deep2}
\citation{nnc}
\newlabel{sec:The-proposed-method}{{2}{3}{The proposed method\label {sec:The-proposed-method}}{section.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}The proposed method}{3}{section.2}\protected@file@percent }
\newlabel{eq:nn}{{2}{3}{The proposed method\label {sec:The-proposed-method}}{equation.2.2}{}}
\newlabel{enu:Main-Step.}{{2}{3}{The proposed method\label {sec:The-proposed-method}}{Item.11}{}}
\citation{de_char}
\citation{powell}
\citation{de_char}
\newlabel{eq:eq1-1}{{4}{4}{The proposed method\label {sec:The-proposed-method}}{equation.2.4}{}}
\newlabel{enu:Testing-step.}{{4}{4}{The proposed method\label {sec:The-proposed-method}}{Item.37}{}}
\citation{uci}
\citation{Keel}
\citation{alcohol}
\citation{australian}
\citation{bands}
\citation{balance}
\citation{cleveland1,cleveland2}
\citation{dermatology}
\citation{ecoli}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The flowchart of the proposed method.\relax }}{5}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:flow_de}{{1}{5}{The flowchart of the proposed method.\relax }{figure.caption.1}{}}
\newlabel{sec:Experiments}{{3}{5}{Experiments \label {sec:Experiments}}{section.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Experiments }{5}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Experimental datasets }{5}{subsection.3.1}\protected@file@percent }
\citation{hayes-roth}
\citation{heart}
\citation{housevotes}
\citation{ion1,ion2}
\citation{liver,liver1}
\citation{lymography}
\citation{magic}
\citation{mammographic}
\citation{pageblocks}
\citation{parkinsons1,parkinsons2}
\citation{pima}
\citation{popfailures}
\citation{regions2}
\citation{saheart}
\citation{segment}
\citation{sonar}
\citation{student}
\citation{transfusion}
\citation{wdbc1,wdbc2}
\citation{wine1,wine2}
\citation{eeg1,eeg2}
\citation{zoo}
\citation{abalone}
\citation{airfoil}
\citation{concrete}
\citation{friedman}
\citation{housing}
\citation{pydataset}
\citation{powell}
\citation{neat}
\citation{rbf1,rbf2}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Experimental results}{7}{subsection.3.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces The values for the parameters of the proposed method.\relax }}{7}{table.caption.2}\protected@file@percent }
\newlabel{tab:settings}{{1}{7}{The values for the parameters of the proposed method.\relax }{table.caption.2}{}}
\citation{prune}
\citation{fcn}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Experimental results for the classification datasets using the series of optimization methods. The numbers presented in the cells represent the average classification error as measured for the corresponding test set using the ten - fold cross validation method.\relax }}{9}{table.caption.3}\protected@file@percent }
\newlabel{tab:experClass}{{2}{9}{Experimental results for the classification datasets using the series of optimization methods. The numbers presented in the cells represent the average classification error as measured for the corresponding test set using the ten - fold cross validation method.\relax }{table.caption.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Experimental results for the provided regression datasets using the series of methods. In each cell the average regression error for each dataset is depicted. This value was calculated using ten - fold cross validation.\relax }}{10}{table.caption.4}\protected@file@percent }
\newlabel{tab:experRegression}{{3}{10}{Experimental results for the provided regression datasets using the series of methods. In each cell the average regression error for each dataset is depicted. This value was calculated using ten - fold cross validation.\relax }{table.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Statistical comparison of the used machine learning models for the classification datasets.\relax }}{12}{figure.caption.5}\protected@file@percent }
\newlabel{fig:statClass}{{2}{12}{Statistical comparison of the used machine learning models for the classification datasets.\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Statistical comparison between the machine learning models for the regression datasets.\relax }}{12}{figure.caption.6}\protected@file@percent }
\newlabel{fig:statRegression}{{3}{12}{Statistical comparison between the machine learning models for the regression datasets.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The average classification error for all methods used in the conducted experiments.\relax }}{13}{figure.caption.7}\protected@file@percent }
\newlabel{fig:averageClass}{{4}{13}{The average classification error for all methods used in the conducted experiments.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Average regression error for the used techniques.\relax }}{13}{figure.caption.8}\protected@file@percent }
\newlabel{fig:averageRegression}{{5}{13}{Average regression error for the used techniques.\relax }{figure.caption.8}{}}
\citation{de_migrant}
\citation{de_dynamic}
\citation{de_char}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Average execution time for the machine learning methods used in the experiments involving the classification datasets.\relax }}{14}{figure.caption.9}\protected@file@percent }
\newlabel{fig:de_time}{{6}{14}{Average execution time for the machine learning methods used in the experiments involving the classification datasets.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Experiments with the differential weight }{14}{subsubsection.3.2.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Experimental results for the classification datasets using a list of proposed differential weight mechanisms found in the literature. Each column denotes a different weight mechanism and numbers in cells stand for the average classification error as measured on the corresponding test set. \relax }}{16}{table.caption.10}\protected@file@percent }
\newlabel{tab:experFClass}{{4}{16}{Experimental results for the classification datasets using a list of proposed differential weight mechanisms found in the literature. Each column denotes a different weight mechanism and numbers in cells stand for the average classification error as measured on the corresponding test set. \relax }{table.caption.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Experimental results for the regression datasets using a variety of differential weigh methods. In every column a different weight mechanism is depicted and numbers in cells represent the average regression error as calculated on the corresponding test set.\relax }}{17}{table.caption.11}\protected@file@percent }
\newlabel{tab:experFWeightRegression}{{5}{17}{Experimental results for the regression datasets using a variety of differential weigh methods. In every column a different weight mechanism is depicted and numbers in cells represent the average regression error as calculated on the corresponding test set.\relax }{table.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Statistical comparison for the obtained results on the classification datasets using a series of differential weight mechanisms. \relax }}{18}{figure.caption.12}\protected@file@percent }
\newlabel{fig:statFclass}{{7}{18}{Statistical comparison for the obtained results on the classification datasets using a series of differential weight mechanisms. \relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Statistical comparison between the various differential weight mechanisms for the regression datasets.\relax }}{19}{figure.caption.13}\protected@file@percent }
\newlabel{fig:statFRegression}{{8}{19}{Statistical comparison between the various differential weight mechanisms for the regression datasets.\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Experiments with the factor $a$ }{19}{subsubsection.3.2.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Experimental results for the classification datasets using different values for the critical parameter $a$. In each column a different value for the critical parameter is used and numbers in cells represent the average classification error.\relax }}{20}{table.caption.14}\protected@file@percent }
\newlabel{tab:experAClass}{{6}{20}{Experimental results for the classification datasets using different values for the critical parameter $a$. In each column a different value for the critical parameter is used and numbers in cells represent the average classification error.\relax }{table.caption.14}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Experimental results for the regression datasets using different values for the critical parameter $a$. Each column contains experiments with different values for the critical parameter $a$. The numbers in cells represent average regression error for the corresponding test set.\relax }}{21}{table.caption.15}\protected@file@percent }
\newlabel{tab:experARegression}{{7}{21}{Experimental results for the regression datasets using different values for the critical parameter $a$. Each column contains experiments with different values for the critical parameter $a$. The numbers in cells represent average regression error for the corresponding test set.\relax }{table.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Statistical comparison for the experiments with different values for the parameter $a$. The method was applied on the classification datasets.\relax }}{22}{figure.caption.16}\protected@file@percent }
\newlabel{fig:statAClass}{{9}{22}{Statistical comparison for the experiments with different values for the parameter $a$. The method was applied on the classification datasets.\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Statistical comparison for the experiments using different values for the parameter $a$. The method was applied on the regression datasets.\relax }}{23}{figure.caption.17}\protected@file@percent }
\newlabel{fig:statARegression}{{10}{23}{Statistical comparison for the experiments using different values for the parameter $a$. The method was applied on the regression datasets.\relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Experiments with the local search rate}{23}{subsubsection.3.2.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Experimental results for the classification datasets using different values of local search rate $p_{l}$. In each column different value for the local search rate is used. Numbers in cells stand for the average classification error as measured on the corresponding test set.\relax }}{24}{table.caption.18}\protected@file@percent }
\newlabel{tab:experPLClass}{{8}{24}{Experimental results for the classification datasets using different values of local search rate $p_{l}$. In each column different value for the local search rate is used. Numbers in cells stand for the average classification error as measured on the corresponding test set.\relax }{table.caption.18}{}}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Experimental results for the regression datasets using different values of the local search rate parameter $p_{l}$. The columns contain experiments with different values of the local search rate and numbers in cells represent average regression error for the corresponding test set.\relax }}{25}{table.caption.19}\protected@file@percent }
\newlabel{tab:experPlRegression}{{9}{25}{Experimental results for the regression datasets using different values of the local search rate parameter $p_{l}$. The columns contain experiments with different values of the local search rate and numbers in cells represent average regression error for the corresponding test set.\relax }{table.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Statistical comparison for the conducted experiments on the classification datasets using the proposed method and different values of local search rate $p_{l}$.\relax }}{26}{figure.caption.20}\protected@file@percent }
\newlabel{fig:statPLClass}{{11}{26}{Statistical comparison for the conducted experiments on the classification datasets using the proposed method and different values of local search rate $p_{l}$.\relax }{figure.caption.20}{}}
\citation{LBFGS}
\citation{Adam}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Statistical comparison for the conducted experiments on the regression datasets using the proposed method and different values of local search rate $p_{l}$.\relax }}{27}{figure.caption.21}\protected@file@percent }
\newlabel{fig:statPLRegression}{{12}{27}{Statistical comparison for the conducted experiments on the regression datasets using the proposed method and different values of local search rate $p_{l}$.\relax }{figure.caption.21}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.4}Experiments with the local search method}{27}{subsubsection.3.2.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces Experimental results for the classification datasets using different local search methods for the classification datasets. Numbers in cells stand for the average classification error as measured on the corresponding test set.\relax }}{28}{table.caption.22}\protected@file@percent }
\newlabel{tab:experLocalClass}{{10}{28}{Experimental results for the classification datasets using different local search methods for the classification datasets. Numbers in cells stand for the average classification error as measured on the corresponding test set.\relax }{table.caption.22}{}}
\@writefile{lot}{\contentsline {table}{\numberline {11}{\ignorespaces Experimental results for the regression datasets using different local search methods.\relax }}{29}{table.caption.23}\protected@file@percent }
\newlabel{tab:experLocalRegression}{{11}{29}{Experimental results for the regression datasets using different local search methods.\relax }{table.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Statistical comparison of the experimental results using the proposed methods and a variety of local optimization techniques for the classification datasets.\relax }}{31}{figure.caption.24}\protected@file@percent }
\newlabel{fig:statLocalClass}{{13}{31}{Statistical comparison of the experimental results using the proposed methods and a variety of local optimization techniques for the classification datasets.\relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Statistical comparison of the experimental results using a variety of local optimization methods applied on the regression datasets.\relax }}{32}{figure.caption.25}\protected@file@percent }
\newlabel{fig:statLocalRegression}{{14}{32}{Statistical comparison of the experimental results using a variety of local optimization methods applied on the regression datasets.\relax }{figure.caption.25}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Summary of experimental results}{32}{subsection.3.3}\protected@file@percent }
\newlabel{sec:Conclusions}{{4}{32}{Conclusions\label {sec:Conclusions} }{section.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusions }{32}{section.4}\protected@file@percent }
\citation{openmpi}
\citation{openmp}
\citation{pde1,pde2}
\bibcite{nn1}{{1}{}{{}}{{}}}
\bibcite{nn2}{{2}{}{{}}{{}}}
\bibcite{nnphysics1}{{3}{}{{}}{{}}}
\bibcite{nnphysics2}{{4}{}{{}}{{}}}
\@writefile{toc}{\contentsline {section}{References}{33}{section.4}\protected@file@percent }
\bibcite{nnphysics3}{{5}{}{{}}{{}}}
\bibcite{nnde1}{{6}{}{{}}{{}}}
\bibcite{nn_solar}{{7}{}{{}}{{}}}
\bibcite{nnagr2}{{8}{}{{}}{{}}}
\bibcite{nnchem1}{{9}{}{{}}{{}}}
\bibcite{nnchem3}{{10}{}{{}}{{}}}
\bibcite{nnecon1}{{11}{}{{}}{{}}}
\bibcite{nnecon2}{{12}{}{{}}{{}}}
\bibcite{nnmed1}{{13}{}{{}}{{}}}
\bibcite{nnmed2}{{14}{}{{}}{{}}}
\bibcite{bpnn1}{{15}{}{{}}{{}}}
\bibcite{bpnn2}{{16}{}{{}}{{}}}
\bibcite{rpropnn-1}{{17}{}{{}}{{}}}
\bibcite{Adam}{{18}{}{{}}{{}}}
\bibcite{nn_ann1}{{19}{}{{}}{{}}}
\bibcite{geneticnn}{{20}{}{{}}{{}}}
\bibcite{psonn}{{21}{}{{}}{{}}}
\bibcite{weight_aco}{{22}{}{{}}{{}}}
\bibcite{tabunn}{{23}{}{{}}{{}}}
\bibcite{nn_hybrid}{{24}{}{{}}{{}}}
\bibcite{nn_cascade}{{25}{}{{}}{{}}}
\bibcite{weight_abc}{{26}{}{{}}{{}}}
\bibcite{nn_init1}{{27}{}{{}}{{}}}
\bibcite{nn_init2}{{28}{}{{}}{{}}}
\bibcite{nn_init3}{{29}{}{{}}{{}}}
\bibcite{nn_init4}{{30}{}{{}}{{}}}
\bibcite{nn_arch1}{{31}{}{{}}{{}}}
\bibcite{nn_arch2}{{32}{}{{}}{{}}}
\bibcite{nn_arch3}{{33}{}{{}}{{}}}
\bibcite{nn_arch4}{{34}{}{{}}{{}}}
\bibcite{nnsharing1}{{35}{}{{}}{{}}}
\bibcite{nnsharing2}{{36}{}{{}}{{}}}
\bibcite{nnprunning1}{{37}{}{{}}{{}}}
\bibcite{nnprunning2}{{38}{}{{}}{{}}}
\bibcite{nnearly1}{{39}{}{{}}{{}}}
\bibcite{nnearly2}{{40}{}{{}}{{}}}
\bibcite{nndecay1}{{41}{}{{}}{{}}}
\bibcite{nndecay2}{{42}{}{{}}{{}}}
\bibcite{de_review}{{43}{}{{}}{{}}}
\bibcite{de1}{{44}{}{{}}{{}}}
\bibcite{de2}{{45}{}{{}}{{}}}
\bibcite{de_symmetry1}{{46}{}{{}}{{}}}
\bibcite{de_symmetry3}{{47}{}{{}}{{}}}
\bibcite{de_symmetry6}{{48}{}{{}}{{}}}
\bibcite{de_symmetry7}{{49}{}{{}}{{}}}
\bibcite{uci}{{50}{1989}{{}}{{}}}
\bibcite{key-16}{{51}{}{{}}{{}}}
\bibcite{de_problem2}{{52}{}{{}}{{}}}
\bibcite{de_problem3}{{53}{}{{}}{{}}}
\bibcite{de_problem4}{{54}{}{{}}{{}}}
\bibcite{de_deep1}{{55}{}{{}}{{}}}
\bibcite{de_deep2}{{56}{}{{}}{{}}}
\bibcite{nn_deep1}{{57}{}{{}}{{}}}
\bibcite{nn_deep2}{{58}{}{{}}{{}}}
\bibcite{nnc}{{59}{}{{}}{{}}}
\bibcite{de_char}{{60}{year}{{Author1}}{{}}}
\bibcite{powell}{{61}{}{{}}{{}}}
\bibcite{Keel}{{62}{}{{}}{{}}}
\bibcite{alcohol}{{63}{2018}{{Tzimourta}}{{}}}
\bibcite{australian}{{64}{2018}{{Quinlan}}{{}}}
\bibcite{bands}{{65}{1994}{{Evans}}{{}}}
\bibcite{balance}{{66}{}{{}}{{}}}
\bibcite{cleveland1}{{67}{2004}{{}}{{}}}
\bibcite{cleveland2}{{68}{}{{}}{{}}}
\bibcite{dermatology}{{69}{1998}{{}}{{}}}
\bibcite{ecoli}{{70}{1996}{{}}{{}}}
\bibcite{hayes-roth}{{71}{1977}{{}}{{}}}
\bibcite{heart}{{72}{1997}{{}}{{}}}
\bibcite{housevotes}{{73}{2002}{{}}{{}}}
\bibcite{ion1}{{74}{2004}{{}}{{}}}
\bibcite{ion2}{{75}{}{{}}{{}}}
\bibcite{liver}{{76}{2002}{{}}{{}}}
\bibcite{liver1}{{77}{}{{}}{{}}}
\bibcite{lymography}{{78}{2002}{{}}{{}}}
\bibcite{magic}{{79}{2002}{{}}{{}}}
\bibcite{mammographic}{{80}{2007}{{}}{{}}}
\bibcite{parkinsons1}{{81}{2007}{{}}{{}}}
\bibcite{parkinsons2}{{82}{}{{}}{{}}}
\bibcite{pima}{{83}{2007}{{}}{{}}}
\bibcite{pageblocks}{{84}{}{{}}{{}}}
\bibcite{popfailures}{{85}{2007}{{}}{{}}}
\bibcite{regions2}{{86}{2007}{{}}{{}}}
\bibcite{saheart}{{87}{2007}{{}}{{}}}
\bibcite{segment}{{88}{}{{}}{{}}}
\bibcite{sonar}{{89}{}{{}}{{}}}
\bibcite{student}{{90}{2007}{{}}{{}}}
\bibcite{transfusion}{{91}{2007}{{}}{{}}}
\bibcite{wdbc1}{{92}{2007}{{}}{{}}}
\bibcite{wdbc2}{{93}{2007}{{}}{{}}}
\bibcite{wine1}{{94}{2007}{{}}{{}}}
\bibcite{wine2}{{95}{}{{}}{{}}}
\bibcite{eeg1}{{96}{2007}{{}}{{}}}
\bibcite{eeg2}{{97}{}{{}}{{}}}
\bibcite{zoo}{{98}{2007}{{}}{{}}}
\bibcite{abalone}{{99}{2007}{{}}{{}}}
\bibcite{airfoil}{{100}{2007}{{}}{{}}}
\bibcite{concrete}{{101}{2007}{{}}{{}}}
\bibcite{friedman}{{102}{}{{}}{{}}}
\bibcite{housing}{{103}{2007}{{}}{{}}}
\bibcite{pydataset}{{104}{}{{}}{{}}}
\bibcite{neat}{{105}{}{{}}{{}}}
\bibcite{rbf1}{{106}{1991}{{}}{{}}}
\bibcite{rbf2}{{107}{}{{}}{{}}}
\bibcite{prune}{{108}{}{{}}{{}}}
\bibcite{fcn}{{109}{}{{}}{{}}}
\bibcite{de_migrant}{{110}{}{{}}{{}}}
\bibcite{de_dynamic}{{111}{}{{}}{{}}}
\bibcite{LBFGS}{{112}{}{{}}{{}}}
\bibcite{openmpi}{{113}{}{{}}{{}}}
\bibcite{openmp}{{114}{}{{}}{{}}}
\bibcite{pde1}{{115}{}{{}}{{}}}
\bibcite{pde2}{{116}{}{{}}{{}}}
\newlabel{LastPage}{{}{37}{}{page.37}{}}
\xdef\lastpage@lastpage{37}
\xdef\lastpage@lastpageHy{37}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\expandafter\ifx\csname c@page@totc\endcsname\relax\newcounter{page@totc}\fi\setcounter{page@totc}{38}
\gdef \@abspage@last{37}
